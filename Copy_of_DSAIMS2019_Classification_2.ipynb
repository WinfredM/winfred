{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DSAIMS2019-Classification 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/winfred-mutinda-crypto/winfred/blob/master/Copy_of_DSAIMS2019_Classification_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs3Vxo5dmP7j"
      },
      "source": [
        "## Feature based classification Prac 2\n",
        "\n",
        "### Data Analytics - AIMS 2019\n",
        "\n",
        "***Dr. Emmanuel Dufourq*** www.emmanueldufourq.com\n",
        "\n",
        "***African Institute for Mathematical Sciences***\n",
        "\n",
        "***Stellenbosch University***\n",
        "\n",
        "***2019***\n",
        "\n",
        "\n",
        "Credits:\n",
        "\n",
        "(extended from https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YkfLWHNyASN"
      },
      "source": [
        "## Task\n",
        "\n",
        "Before starting with the implementation of a neural network ask yourself these questions:\n",
        "\n",
        "1) What is a classification problem?\n",
        "\n",
        "2) What can we expect the outputs values to be?\n",
        "\n",
        "3) How many inputs would a neural network have if we tried to solve such a problem?\n",
        "\n",
        "4) How many outputs would a neural network have?\n",
        "\n",
        "5) What we want the network to output?\n",
        "\n",
        "6) Which loss function would we use?\n",
        "\n",
        "7) What would be a good strategy to take when designing the network?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpvo-bqTmP7m"
      },
      "source": [
        "## Imports first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvCXvXq5mP7p"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1GTR35cmP7v"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ_KjFJomP7x"
      },
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-Lw_bPQKQFX"
      },
      "source": [
        "## View the shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pukHaddPASl"
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVFAoAMmOruJ",
        "outputId": "c617a7bc-c1dc-4c74-884f-c09ea302930b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print('Training data shape : ', X_train.shape, Y_train.shape)\n",
        "print('Validation data shape : ', X_val.shape, Y_val.shape)\n",
        "print('Testing data shape : ', X_test.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape :  (42000, 28, 28) (42000,)\n",
            "Validation data shape :  (18000, 28, 28) (18000,)\n",
            "Testing data shape :  (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z51sdOntmP78"
      },
      "source": [
        "## Find the unique numbers from the train labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o29O_gUTmP79",
        "outputId": "8610c864-8a17-4612-a81e-bbdefb835739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "classes = np.unique(Y_train)\n",
        "nClasses = len(classes)\n",
        "print('Total number of outputs : ', nClasses)\n",
        "print('Output classes : ', classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of outputs :  10\n",
            "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMMjLgbimP8B"
      },
      "source": [
        "## Plot some of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQpW4rajmP8C",
        "outputId": "be48d432-f790-478d-d9f8-93ac8106acdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "plt.figure(figsize=[10,5])\n",
        " \n",
        "# Display the first image in training data\n",
        "plt.subplot(121)\n",
        "plt.imshow(X_train[0,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(Y_train[0]))\n",
        " \n",
        "# Display the first image in testing data\n",
        "plt.subplot(122)\n",
        "plt.imshow(X_test[0,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(Y_test[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ground Truth : 7')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAEtCAYAAADHtl7HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAADIRIACAADIRIACAADIRIACAADI9P8BHhb1XDPSMMoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsiC1XaCyxSd"
      },
      "source": [
        "## Task\n",
        "\n",
        "The dataset contains images and 1 target class.\n",
        "\n",
        "Each image is 28x28 pixels in size.\n",
        "\n",
        "But a picture is a matrix of values, so we can flatten out the values into a long vector of length 784 (28x28). Thus, there are 784 features.\n",
        "\n",
        "The different classes are as follows: 1,2,3,4,5,6,7,8,9,0 each representing a class and not a numerical value like in a regression problem.\n",
        "\n",
        "1) How many inputs would a neural network have if we tried to solve this problem?\n",
        "\n",
        "2) How many outputs would the neural network have?\n",
        "\n",
        "3) What is the goal here? What are we trying to achieve with machine learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PY8KLU-mP8H"
      },
      "source": [
        "## Flatten the data\n",
        "\n",
        "In this notebook we won't be making use of the data as \"images\" but rather as long vectors of length 784"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVo2Tj7smP8I"
      },
      "source": [
        "## This is what an example in the dataset looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtB2Fh5emP8J",
        "outputId": "bff08bb1-e438-4dba-b664-affecc4c4aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCIx4MeZmP8N",
        "outputId": "6dd655c2-fb37-4526-b80b-eff067483f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01568627, 0.08627451, 0.51372549,\n",
              "       0.51372549, 0.51372549, 0.51372549, 0.8745098 , 0.87058824,\n",
              "       0.51372549, 0.12156863, 0.01960784, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.58431373, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.83921569, 0.36078431, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.58431373, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.42352941, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.29411765, 0.89803922, 0.89803922, 0.89803922,\n",
              "       0.80392157, 0.51764706, 0.54117647, 0.78039216, 0.92941176,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.09411765,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.59215686, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.75686275, 0.03921569, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.24705882,\n",
              "       0.92156863, 0.99607843, 0.99607843, 0.99607843, 0.29803922,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.49019608, 0.91764706, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.67058824, 0.04313725, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.23137255, 0.68235294, 0.91372549,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.76078431, 0.04705882,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.47058824,\n",
              "       0.90588235, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.92941176, 0.2745098 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.54117647, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.75686275, 0.04313725,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.04313725, 0.39215686, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.63137255, 0.17254902, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.04313725,\n",
              "       0.21568627, 0.57254902, 0.78431373, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.91764706, 0.23921569, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.05490196, 0.66666667, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.92156863, 0.07843137, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.4627451 ,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.09411765,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.41176471, 0.96862745, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.09411765, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.2627451 , 0.31764706, 0.        , 0.64705882, 0.96862745,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.4627451 ,\n",
              "       0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.11372549, 0.90588235, 0.96470588, 0.98039216,\n",
              "       0.90588235, 0.97254902, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.84313725, 0.07058824, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.1254902 ,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.64313725, 0.15294118, 0.04705882,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00784314, 0.42745098, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.49411765,\n",
              "       0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.00392157, 0.34509804, 0.60392157, 1.        ,\n",
              "       0.63921569, 0.38039216, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doXYy1uzKWjA"
      },
      "source": [
        "## Task: Convert from image shape to a vector shape\n",
        "\n",
        "We go from 28x28 pixel sized images to a vector of length 784.\n",
        "\n",
        "We would like to reshape the training data `X_train` from shape (60000, 28, 28) to (60000,784). To do this, we can make use of Numpy's *reshape* function. \n",
        "\n",
        "Hint: Below I show you how to do it for `X_train`, you will need to do it for the testing features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N_KASYwI0MB"
      },
      "source": [
        "X_train = np.reshape(X_train, (42000, 784))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ70mEZoV3I-",
        "outputId": "1090bad4-f1c0-44c4-da42-92fc75808644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5f0gLa8Vsj_"
      },
      "source": [
        "X_test = np.reshape(X_test, (10000, 784))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kICREe5MtdfJ",
        "outputId": "6ea7b8d8-a109-4393-9bad-ddc3c3bdc04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAvNzShjmP8U"
      },
      "source": [
        "## Now the data is a long vector\n",
        "\n",
        "There are 60,000 examples for which each is a vector of length 784"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQW62Xe0mP8V",
        "outputId": "315e7976-1984-4c22-8fa3-036622913cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPx7o41CK2S-"
      },
      "source": [
        "## View the first example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNkeCMoUmP8Y",
        "outputId": "035e79f8-6e8d-4325-c3f8-79cf1a50e7e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01568627, 0.08627451, 0.51372549,\n",
              "       0.51372549, 0.51372549, 0.51372549, 0.8745098 , 0.87058824,\n",
              "       0.51372549, 0.12156863, 0.01960784, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.58431373, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.83921569, 0.36078431, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.58431373, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.42352941, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.29411765, 0.89803922, 0.89803922, 0.89803922,\n",
              "       0.80392157, 0.51764706, 0.54117647, 0.78039216, 0.92941176,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.09411765,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.59215686, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.75686275, 0.03921569, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.24705882,\n",
              "       0.92156863, 0.99607843, 0.99607843, 0.99607843, 0.29803922,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.49019608, 0.91764706, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.67058824, 0.04313725, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.23137255, 0.68235294, 0.91372549,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.76078431, 0.04705882,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.47058824,\n",
              "       0.90588235, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.92941176, 0.2745098 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.54117647, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.75686275, 0.04313725,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.04313725, 0.39215686, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.63137255, 0.17254902, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.04313725,\n",
              "       0.21568627, 0.57254902, 0.78431373, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.91764706, 0.23921569, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.05490196, 0.66666667, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.92156863, 0.07843137, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.4627451 ,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.09411765,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.41176471, 0.96862745, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.09411765, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.2627451 , 0.31764706, 0.        , 0.64705882, 0.96862745,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.4627451 ,\n",
              "       0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.11372549, 0.90588235, 0.96470588, 0.98039216,\n",
              "       0.90588235, 0.97254902, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.84313725, 0.07058824, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.1254902 ,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.64313725, 0.15294118, 0.04705882,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00784314, 0.42745098, 0.99607843,\n",
              "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.49411765,\n",
              "       0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.00392157, 0.34509804, 0.60392157, 1.        ,\n",
              "       0.63921569, 0.38039216, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BykRwF2UmP8b"
      },
      "source": [
        "## Task: Normalise\n",
        "\n",
        "We need to normalise the data since the values range from 0 to 255. Training NNs on data ranging between [0,1] can be easier. To do this, we simply divide by the maximum value, in this case 255. So here you need to divide each split by 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH2lcHF3mP8c"
      },
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIX6XhnfyXKT",
        "outputId": "06909335-545d-4971-88ef-d2acbec3bf1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.15148020e-05,\n",
              "       3.38331411e-04, 2.01460977e-03, 2.01460977e-03, 2.01460977e-03,\n",
              "       2.01460977e-03, 3.42945021e-03, 3.41407151e-03, 2.01460977e-03,\n",
              "       4.76739715e-04, 7.68935025e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.29142637e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 3.29104191e-03, 1.41484045e-03, 3.07574010e-05,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.29142637e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 1.66089965e-03,\n",
              "       3.07574010e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.15340254e-03,\n",
              "       3.52172241e-03, 3.52172241e-03, 3.52172241e-03, 3.15263360e-03,\n",
              "       2.02998847e-03, 2.12226067e-03, 3.06036140e-03, 3.64475202e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.69088812e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.32218378e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 2.96808920e-03,\n",
              "       1.53787005e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 9.68858131e-04, 3.61399462e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 1.16878124e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.92233756e-03, 3.59861592e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 2.62975779e-03, 1.69165705e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.07343329e-04,\n",
              "       2.67589389e-03, 3.58323722e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 2.98346790e-03, 1.84544406e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.84544406e-03, 3.55247982e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.64475202e-03, 1.07650903e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.12226067e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       2.96808920e-03, 1.69165705e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.69165705e-04, 1.53787005e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 2.47597078e-03, 6.76662822e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.69165705e-04,\n",
              "       8.45828527e-04, 2.24529027e-03, 3.07574010e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.59861592e-03, 9.38100730e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.15301807e-04, 2.61437908e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 3.61399462e-03,\n",
              "       3.07574010e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.81468666e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.69088812e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.61476355e-03, 3.79853902e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.69088812e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.03037293e-03, 1.24567474e-03,\n",
              "       0.00000000e+00, 2.53748558e-03, 3.79853902e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 1.81468666e-03,\n",
              "       4.61361015e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       4.45982314e-04, 3.55247982e-03, 3.78316032e-03, 3.84467512e-03,\n",
              "       3.55247982e-03, 3.81391772e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.30642061e-03, 2.76816609e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       4.92118416e-04, 3.90618993e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       2.52210688e-03, 5.99769319e-04, 1.84544406e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.07574010e-05, 1.67627835e-03, 3.90618993e-03, 3.90618993e-03,\n",
              "       3.90618993e-03, 3.90618993e-03, 3.90618993e-03, 1.93771626e-03,\n",
              "       4.61361015e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.53787005e-05, 1.35332564e-03, 2.36831988e-03,\n",
              "       3.92156863e-03, 2.50672818e-03, 1.49173395e-03, 3.07574010e-05,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj0QhPSsmP8e"
      },
      "source": [
        "## One hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQWHZ6FumP8f"
      },
      "source": [
        "We're going to want our labels as one-hot vectors, which are vectors that holds mostly 0's and one 1. It's easiest to see this in a example. As a one-hot vector, the number 0 is represented as [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], and 4 is represented as [0, 0, 0, 0, 1, 0, 0, 0, 0, 0].\n",
        "\n",
        "One-hot encoded vectors allow us to map each category in our set of labels to a vector where only a single value is 1.\n",
        "\n",
        "0 maps to [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "1 maps to [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "2 maps to [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "Notes on one-hot encoding: https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGRXrRTYmP8g"
      },
      "source": [
        "## Before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrKyI7DamP8g",
        "outputId": "88659366-0cf7-4a81-a084-161fdae3e063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfClFp-6K7P6"
      },
      "source": [
        "## Task: Convert from categorical labels to one-hot encoded vectors\n",
        "\n",
        "In this case there are 10 classes so we can tell the function to convert into a vector of length 10. You need to convert both the training targets and the testing targets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3xjsPnVmP8j"
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
        "Y_val = np_utils.to_categorical(Y_val, num_classes)\n",
        "Y_test = np_utils.to_categorical(Y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92H9U6LkmP8m"
      },
      "source": [
        "## After"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiiXZrnUmP8n",
        "outputId": "6fc1f73e-e69f-42c0-a20d-687384dd7375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "Y_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbbTQmv-RTMK"
      },
      "source": [
        "Check the new shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNG6tbpcRWyv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f9ea5b63-06b0-4652-9eaa-5ea6418c8a91"
      },
      "source": [
        "print (Y_train.shape)\n",
        "print (Y_val.shape)\n",
        "print (Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 10, 10)\n",
            "(18000, 10, 10)\n",
            "(10000, 10, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VungsdeHmP8u"
      },
      "source": [
        "## Task: Create a neural network model\n",
        "\n",
        "* You will have to define a model\n",
        "* You can add a number of dense layers\n",
        "* Remember to specify and intput dimension for the first layer (this is always  the case for the first layer only)\n",
        "* You will have to compile the model and define a metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gozmsPxhmP8v"
      },
      "source": [
        "def baseline_model():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(128, input_dim=784, activation='relu'))\n",
        "\n",
        "    model.add(Dropout(rate = 0.4))\n",
        "\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "\n",
        "    model.add(Dropout(rate = 0.4))\n",
        "    \n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_aNPZE0W2V9"
      },
      "source": [
        "## Task: Initialise the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q03EcUrxmP8x"
      },
      "source": [
        "model = baseline_model()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUN6K31smP80"
      },
      "source": [
        "## Task: Determine the number of trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DxDanOHmP80",
        "outputId": "f02bb5b4-3c2e-4816-a8b4-f09da573399d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifPs0mftmP84"
      },
      "source": [
        "## Task: Begin training\n",
        "\n",
        "Fit on the training features and targets. Also make use of the validation data you've set aside above. Set the number of epochs, batch size and also explore various *verbose* values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8RZc1rhmP84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "f59f3ccf-4998-48d7-a46e-9d39ea7330b0"
      },
      "source": [
        "history = model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=10, batch_size=8, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-80c6cb14c44c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_12 to have 2 dimensions, but got array with shape (42000, 10, 10)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9do3Cl8vmP87"
      },
      "source": [
        "## Predict on one example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnI4SnbEmP88"
      },
      "source": [
        "model.predict_classes(np.expand_dims(X_test[0], axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j9LecHgmP8_"
      },
      "source": [
        "## Task: Predict on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TtfkDWjmP8_"
      },
      "source": [
        "predictions = # Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBmZspLUmP9C"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo4UgmBvmP9F"
      },
      "source": [
        "## Task: Compute the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwJwKLwRmP9G"
      },
      "source": [
        "correct_values = # Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7keRohxmP9H"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}